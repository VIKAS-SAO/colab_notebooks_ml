{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import time\nimport seaborn as sns\nimport matplotlib.pyplot as plt \nfrom sklearn.preprocessing import LabelEncoder \nfrom sklearn.model_selection import train_test_split\n\ndata = pd.read_csv('../input/titanic/train.csv')\ndata = data.drop(['PassengerId' , 'Name' , 'Ticket' ,'Cabin' ] , axis = 'columns')\nprint(data.shape)\ndata.head()\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nle =LabelEncoder()\nlabel =le.fit_transform(data['Sex'])\ndata =data.drop(['Sex'] , axis = 'columns')\ndata['Sex'] = label\n\nreplacer =[]\n\nfor i in data['Embarked']:\n    if i=='S':\n        replacer.append(1)\n    else:\n        replacer.append(0)\n\ndata['Embarked'].replace('S',1)\ndata =data.drop(['Embarked'] , axis = 'columns')\ndata['Embarked'] = replacer\n\nfor col in data.columns:\n    data[col] = data[col].fillna(data[col].mean())\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_score(model , X_train , X_test , Y_train , Y_test):\n    model.fit(X_train ,Y_train)\n    return model.score(X_test ,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#classification models\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.neural_network import MLPClassifier\n\nmodelNames=['DecisionTreeClassifier', 'RandomForestClassifier',\n            'KNeighborsClassifier', 'GaussianNB', \n            'LogisticRegression', 'svm', 'MLPClassifier']\nmodel = [DecisionTreeClassifier() , \n        RandomForestClassifier(),\n       KNeighborsClassifier() ,  \n       GaussianNB(),\n       LogisticRegression(),\n       svm.LinearSVC(),\n        MLPClassifier(random_state=1, max_iter=300)\n        ]\n#evaluation\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature selection \n\nfrom sklearn.feature_selection import SelectKBest, chi2 ,  RFE\nX = data.drop(['Survived'] , axis = 'columns')\nY = data['Survived']\n\nsel_f = SelectKBest(chi2, k = 7).fit(X,Y)\nsel_bool =sel_f.get_support()\nsel_f = X[X.columns[sel_bool]]\nX =X[sel_f.columns]\nX_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.20, random_state=0)\n\nfor i in model:\n    if i == svm.LinearSVC():\n        continue\n    print(i, get_score(i,X_train, X_test, Y_train, Y_test ))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# recursive fe\n\nfor i in model:\n    if i==model[2]:\n        continue\n    if i==model[3]:\n        continue\n    if i==model[4]:\n        continue\n    \n    \n    selection  =  RFE(i , n_features_to_select = 3)\n    selection.fit(X,Y)\n    X_sel =  selection.transform(X)\n    sel_bool=selection.get_support()\n    sel_f = X[X.columns[sel_bool]]\n    print(i, get_score(i,X_train, X_test, Y_train, Y_test ))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# k fold cross validation \nfrom sklearn.model_selection import KFold , StratifiedKFold ,cross_val_score , LeaveOneOut , RepeatedKFold\n\n\n\nkf = KFold(n_splits = 3) \n# for train_index , test_index, in kf.split([1,2,3,4,5,6,7,8,9]):\n#     print(train_index ,test_index)\n    \n\n \n\nfor train_index ,test_index in kf.split(X): \n    X_train, X_test ,Y_train   , Y_test =  X.loc[train_index] ,\\\n                   X.loc[test_index]  , Y.loc[train_index], Y.loc[test_index]\n    \n    for i in model:\n        \n        print(i , get_score(i  , X_train, X_test ,Y_train   , Y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cross validation  score\n\nfor i in model:\n    print(cross_val_score(i , X,Y ,scoring = 'accuracy' ,cv =  3))\n    \n#consluction  -the best model is randomforest classifier\n\n\n \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = StratifiedKFold(n_splits = 3)\nscores=[]\n\nfor train_index, test_index in folds.split(X,Y):\n    X_train, X_test ,Y_train   , Y_test =  X.loc[train_index] ,\\\n                   X.loc[test_index]  , Y.loc[train_index], Y.loc[test_index]\n    \n    for i in model:\n        print(i , get_score(i  , X_train, X_test ,Y_train   , Y_test))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\nresult = cross_val_score(estimator=model[1] , X=X,y=Y, scoring  ='accuracy' , cv = KFold(n_splits =5) )\nprint(result , time.time()-start)\n# result = cross_val_score(estimator=model[0] , X=X,y=Y, scoring  ='accuracy' , cv = LeaveOneOut() )\nstart = time.time()\nresult = cross_val_score(estimator=model[1] , X=X,y=Y, scoring  ='accuracy' , cv = StratifiedKFold(n_splits =5) )\nprint(result , time.time()-start)\nstart = time.time()\nresult = cross_val_score(estimator=model[1] , X=X,y=Y, scoring  ='accuracy' , cv = RepeatedKFold(n_splits =5 , n_repeats =5) )\nprint(result , time.time()-start)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}