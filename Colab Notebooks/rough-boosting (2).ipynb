{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":5,"outputs":[{"output_type":"stream","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import time\nimport seaborn as sns\nimport matplotlib.pyplot as plt \nfrom sklearn.preprocessing import LabelEncoder \nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')\n\n \ndata = pd.read_csv('../input/titanic/train.csv')\ndata = data.drop(['PassengerId' , 'Name' , 'Ticket' ,'Cabin' ] , axis = 'columns')\n\ndef get_score(model , X_train , X_test, Y_train , Y_test):\n\tmodel.fit(X_train ,Y_train)\n\treturn model.score(X_test ,Y_test)\n\ndef fill_missing(data):\n    for col in data.columns:\n        data[col] = data[col].fillna(data[col].mean())\n \n        \nle =LabelEncoder()\nlabel =le.fit_transform(data['Sex'])\ndata =data.drop(['Sex'] , axis = 'columns')\ndata['Sex'] = label\n\nreplacer =[]\n\nfor i in data['Embarked']:\n    if i=='S':\n        replacer.append(1)\n    else:\n        replacer.append(0)\n\ndata['Embarked'].replace('S',1)\ndata =data.drop(['Embarked'] , axis = 'columns')\ndata['Embarked'] = replacer\n\nfill_missing(data)\n\n\nX = data.drop(['Survived'] , axis = 'columns')\nY = data['Survived']\nX.head()\n \n\n \n","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"   Pclass   Age  SibSp  Parch     Fare  Sex  Embarked\n0       3  22.0      1      0   7.2500    1         1\n1       1  38.0      1      0  71.2833    0         0\n2       3  26.0      0      0   7.9250    0         1\n3       1  35.0      1      0  53.1000    0         1\n4       3  35.0      0      0   8.0500    1         1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Sex</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.20, random_state=0)\n#classification models\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import AdaBoostClassifier , GradientBoostingClassifier\n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adaboosting\n\n\nmodel =DecisionTreeClassifier(criterion = 'entropy',  max_depth =1)\nadaboost = AdaBoostClassifier(base_estimator=model  , n_estimators=100 ,learning_rate=1)\nada_model = adaboost.fit(X_train ,Y_train)\nY_pred = ada_model .predict(X_test)\nprint('for decision tree model = ' , get_score(model ,X_train, X_test, Y_train, Y_test))\nprint('for the adaboosting model = ' , get_score(ada_model ,X_train, X_test, Y_train, Y_test))\n","execution_count":56,"outputs":[{"output_type":"stream","text":"for decision tree model =  0.7877094972067039\nfor the adaboosting model =  0.8100558659217877\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gradientboosting\n\n\nmodel =DecisionTreeClassifier(criterion = 'entropy',  max_depth =1)\ngradientboost = GradientBoostingClassifier(  n_estimators=100 ,learning_rate=1 , max_depth=1 ,random_state=0)\n\ngradient_model = gradientboost.fit(X_train ,Y_train)\nY_pred = gradient_model .predict(X_test)\nprint('for decision tree model = ' , get_score(model ,X_train, X_test, Y_train, Y_test))\nprint('for the adaboosting model = ' , get_score(gradient_model ,X_train, X_test, Y_train, Y_test))\n","execution_count":57,"outputs":[{"output_type":"stream","text":"for decision tree model =  0.7877094972067039\nfor the adaboosting model =  0.8212290502793296\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#parameter tuning\nfrom sklearn.model_selection import GridSearchCV\nparam_grid   = {\n    'learning_rate':[.1,.2,1,2] ,\n    'n_estimators':[100,500,250] , \n    'max_depth':[2],\n    'random_state':[0]\n}\n\n\ngrid_search_cv   = GridSearchCV(param_grid=param_grid ,estimator =  GradientBoostingClassifier() , scoring='accuracy')\ngrid_search_cv.fit(X_train , Y_train)\nprint('for decision tree model = ' , get_score(model ,X_train, X_test, Y_train, Y_test))\nprint('for the tuned model = ' , get_score(grid_search_cv ,X_train, X_test, Y_train, Y_test))\n","execution_count":66,"outputs":[{"output_type":"stream","text":"for decision tree model =  0.7877094972067039\nfor the tuned model =  0.2924901185770752\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_search_cv.best_params_)\nprint(grid_search_cv.best_score_)\n","execution_count":9,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'grid_search_cv' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-3ef81b6006f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'grid_search_cv' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#xgboost\nfrom xgboost import XGBClassifier\n\nstart = time.time()\n\nxgboost = XGBClassifier(eta=1.0 ,gamma=10)\nxgboost.fit(X_train , Y_train)\nprint('for decision tree model = ' , get_score(model ,X_train, X_test, Y_train, Y_test) ,'time = ',time.time()-start)\nstart = time.time()\nprint('score for xgbclassfifier = '  ,get_score(xgboost,X_train, X_test, Y_train, Y_test ) , 'time = ' ,time.time()-start)\n\n\n","execution_count":24,"outputs":[{"output_type":"stream","text":"for decision tree model =  0.8212290502793296 time =  0.13348746299743652\nscore for xgbclassfifier =  0.8268156424581006 time =  0.0725712776184082\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#paramater tuning xgboosting\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid   = {\n    'eta':[.1,.2,1,2,3] ,\n    'gamma':[1,10,100,500] \n}\n\n\ngrid_search_cv   = GridSearchCV(param_grid=param_grid ,estimator =  XGBClassifier() , scoring='accuracy')\ngrid_search_cv.fit(X_train , Y_train)\nprint('for decision tree model = ' , get_score(model ,X_train, X_test, Y_train, Y_test))\nprint('for the tuned xgboost model = ' , get_score(grid_search_cv ,X_train, X_test, Y_train, Y_test))\n\n\n\n","execution_count":33,"outputs":[{"output_type":"stream","text":"for decision tree model =  0.8212290502793296\nfor the tuned xgboost model =  0.8491620111731844\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_search_cv.best_params_)\nprint(grid_search_cv.best_score_)\n","execution_count":34,"outputs":[{"output_type":"stream","text":"{'eta': 0.1, 'gamma': 1}\n0.8356446370530879\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}