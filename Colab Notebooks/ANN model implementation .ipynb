{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sys\n",
    "import copy\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "from zipfile import ZipFile \n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  affordibility  bought_insurance\n",
       "0  0.22              1                 0\n",
       "1  0.25              0                 0\n",
       "2  0.47              1                 1\n",
       "3  0.52              0                 0\n",
       "4  0.46              1                 1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('insurance_data.csv')\n",
    "data['age'] =data['age']/100\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  affordibility\n",
       "17  0.58              1\n",
       "12  0.27              0\n",
       "4   0.46              1\n",
       "5   0.56              1\n",
       "11  0.28              1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train ,X_test , Y_train, Y_test   = train_test_split(data[['age' , 'affordibility']] , data['bought_insurance'])\n",
    "# X_train['age']=X_train['age']/100\n",
    "# X_test['age']=X_test['age']/100\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7406 - accuracy: 0.5238\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7402 - accuracy: 0.5238\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7398 - accuracy: 0.5238\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.5238\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7389 - accuracy: 0.5238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f9da418a30>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model   = keras.Sequential([\n",
    "    keras.layers.Dense(1 ,input_shape=(2 ,) ,activation = 'sigmoid' , kernel_initializer='ones' ,bias_initializer = 'zeros' )\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam' , \n",
    "    loss='binary_crossentropy' ,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, Y_train ,epochs=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6403 - accuracy: 0.4286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.99500155],\n",
       "        [0.9950009 ]], dtype=float32),\n",
       " array([-0.00499922], dtype=float32))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test , Y_test)\n",
    "coef  , intercept = model.get_weights()\n",
    "coef , intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 0 ,log loss -0.6420452745328359  \n",
      "epochs 1 ,log loss -0.6051080817105208  \n",
      "epochs 2 ,log loss -0.5762705632692358  \n",
      "epochs 3 ,log loss -0.5537260226883632  \n",
      "epochs 4 ,log loss -0.5359311256899215  \n",
      "epochs 5 ,log loss -0.5216468144130101  \n",
      "epochs 6 ,log loss -0.5099233532561087  \n",
      "epochs 7 ,log loss -0.500057148681331  \n",
      "epochs 8 ,log loss -0.49153954317622883  \n",
      "epochs 9 ,log loss -0.48400895914186687  \n",
      "epochs 10 ,log loss -0.4772111337526913  \n",
      "epochs 11 ,log loss -0.470968297809015  \n",
      "epochs 12 ,log loss -0.4651563301868852  \n",
      "epochs 13 ,log loss -0.4596883225628012  \n",
      "epochs 14 ,log loss -0.45450299516305875  \n",
      "epochs 15 ,log loss -0.44955664649521193  \n",
      "epochs 16 ,log loss -0.44481761349736  \n",
      "epochs 17 ,log loss -0.4402624846267376  \n",
      "epochs 18 ,log loss -0.4358735224937144  \n",
      "epochs 19 ,log loss -0.4316369142072697  \n",
      "epochs 20 ,log loss -0.4275415848918243  \n",
      "epochs 21 ,log loss -0.4235783928905231  \n",
      "epochs 22 ,log loss -0.4197395830021273  \n",
      "epochs 23 ,log loss -0.416018413904796  \n",
      "epochs 24 ,log loss -0.4124089030985318  \n",
      "epochs 25 ,log loss -0.40890565115003624  \n",
      "epochs 26 ,log loss -0.40550371950175695  \n",
      "epochs 27 ,log loss -0.40219854452237225  \n",
      "epochs 28 ,log loss -0.39898587614145725  \n",
      "epochs 29 ,log loss -0.3958617332211575  \n",
      "epochs 30 ,log loss -0.392822370378581  \n",
      "epochs 31 ,log loss -0.3898642526936947  \n",
      "epochs 32 ,log loss -0.3869840358943997  \n",
      "epochs 33 ,log loss -0.3841785503885063  \n",
      "epochs 34 ,log loss -0.3814447880359338  \n",
      "epochs 35 ,log loss -0.37877989090719194  \n",
      "epochs 36 ,log loss -0.3761811415120691  \n",
      "epochs 37 ,log loss -0.3736459541430907  \n",
      "epochs 38 ,log loss -0.3711718670869834  \n",
      "epochs 39 ,log loss -0.36875653553102844  \n",
      "epochs 40 ,log loss -0.366397725041253  \n",
      "epochs 41 ,log loss -0.36409330552352187  \n",
      "epochs 42 ,log loss -0.3618412456019673  \n",
      "epochs 43 ,log loss -0.35963960736527023  \n",
      "epochs 44 ,log loss -0.35748654144245867  \n",
      "epochs 45 ,log loss -0.3553802823777024  \n",
      "epochs 46 ,log loss -0.35331914427910244  \n",
      "epochs 47 ,log loss -0.3513015167204646  \n",
      "epochs 48 ,log loss -0.3493258608779607  \n",
      "epochs 49 ,log loss -0.3473907058857743  \n",
      "epochs 50 ,log loss -0.3454946453965162  \n",
      "epochs 51 ,log loss -0.3436363343335328  \n",
      "epochs 52 ,log loss -0.341814485823319  \n",
      "epochs 53 ,log loss -0.34002786829716486  \n",
      "epochs 54 ,log loss -0.3382753027519464  \n",
      "epochs 55 ,log loss -0.33655566016066224  \n",
      "epochs 56 ,log loss -0.33486785902393656  \n",
      "epochs 57 ,log loss -0.3332108630542634  \n",
      "epochs 58 ,log loss -0.33158367898528346  \n",
      "epochs 59 ,log loss -0.32998535449885436  \n",
      "epochs 60 ,log loss -0.32841497626311783  \n",
      "epochs 61 ,log loss -0.3268716680751767  \n",
      "epochs 62 ,log loss -0.3253545891023761  \n",
      "epochs 63 ,log loss -0.32386293221654494  \n",
      "epochs 64 ,log loss -0.3223959224158919  \n",
      "epochs 65 ,log loss -0.32095281532956366  \n",
      "epochs 66 ,log loss -0.3195328958001746  \n",
      "epochs 67 ,log loss -0.31813547653989405  \n",
      "epochs 68 ,log loss -0.316759896855941  \n",
      "epochs 69 ,log loss -0.31540552144158457  \n",
      "epochs 70 ,log loss -0.31407173922897563  \n",
      "epochs 71 ,log loss -0.3127579623003615  \n",
      "epochs 72 ,log loss -0.31146362485442963  \n",
      "epochs 73 ,log loss -0.3101881822247278  \n",
      "epochs 74 ,log loss -0.30893110994728473  \n",
      "epochs 75 ,log loss -0.307691902874722  \n",
      "epochs 76 ,log loss -0.3064700743343146  \n",
      "epochs 77 ,log loss -0.305265155327599  \n",
      "epochs 78 ,log loss -0.30407669376927354  \n",
      "epochs 79 ,log loss -0.30290425376326496  \n",
      "epochs 80 ,log loss -0.30174741491395923  \n",
      "epochs 81 ,log loss -0.30060577167071184  \n",
      "epochs 82 ,log loss -0.29947893270386045  \n",
      "epochs 83 ,log loss -0.29836652031056454  \n",
      "epochs 84 ,log loss -0.2972681698488984  \n",
      "epochs 85 ,log loss -0.29618352919870355  \n",
      "epochs 86 ,log loss -0.2951122582478042  \n",
      "epochs 87 ,log loss -0.2940540284022576  \n",
      "epochs 88 ,log loss -0.293008522119396  \n",
      "epochs 89 ,log loss -0.29197543246247715  \n",
      "epochs 90 ,log loss -0.2909544626758379  \n",
      "epochs 91 ,log loss -0.2899453257794965  \n",
      "epochs 92 ,log loss -0.28894774418221497  \n",
      "epochs 93 ,log loss -0.28796144931208756  \n",
      "epochs 94 ,log loss -0.2869861812637668  \n",
      "epochs 95 ,log loss -0.28602168846149645  \n",
      "epochs 96 ,log loss -0.2850677273371588  \n",
      "epochs 97 ,log loss -0.28412406202259094  \n",
      "epochs 98 ,log loss -0.2831904640554644  \n",
      "epochs 99 ,log loss -0.28226671209805937  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.3855759285787688, 2.6470411801510223, -2.7754217070718625)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return (1/(1+math.exp(-x)))\n",
    "def prediction_function(age, affordibility):\n",
    "    weighted_sum = coef[0]*age +coef[1]*affordibility+intercept[0]\n",
    "    return sigmoid(weighted_sum)\n",
    "def sigmoid_numpy(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "def log_loss(Y_true, Y_pred):\n",
    "    epsilon  =1e-15\n",
    "    Y_pred_new = [max(i,epsilon) for i in Y_pred]\n",
    "    Y_pred_new = [min(1-epsilon , i) for i in Y_pred]\n",
    "    Y_pred_new =np.array(Y_pred_new)\n",
    "    return np.mean(Y_true*np.log(Y_pred_new) +(1-Y_true)*np.log(1-Y_pred_new))\n",
    "def gradient_descent(age , affordibility , Y_true ,epochs):\n",
    "    w1=w2 =1 \n",
    "    bias =0 \n",
    "    rate = .5\n",
    "    n =len(age)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        weighted_sum = w1*age+w2*affordibility+bias\n",
    "        Y_pred = sigmoid_numpy(weighted_sum)\n",
    "        logloss = log_loss(Y_true , Y_pred)\n",
    "        \n",
    "        w1d  = (1/n)*np.dot(np.transpose(age) , (Y_pred -Y_true))\n",
    "        w2d  = (1/n)*np.dot(np.transpose(affordibility) , (Y_pred - Y_true))\n",
    "        \n",
    "        bias_d =np.mean(Y_pred-Y_true)\n",
    "        \n",
    "        w1 -=w1d*rate\n",
    "        w2-=w2d*rate\n",
    "        bias-=bias_d*rate\n",
    "        print('epochs {} ,log loss {}  '.format(i ,logloss ))\n",
    "        \n",
    "    return w1,w2,bias\n",
    "\n",
    "        \n",
    "    \n",
    "     \n",
    "\n",
    "\n",
    "gradient_descent(X_test['age'] , X_test['affordibility'],Y_test , 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99500155]\n",
      " [0.9950009 ]] [-0.00499922]\n"
     ]
    }
   ],
   "source": [
    "print(coef , intercept)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
