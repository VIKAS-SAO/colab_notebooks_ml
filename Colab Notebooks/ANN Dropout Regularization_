{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ANN Dropout Regularization ","provenance":[],"collapsed_sections":[],"mount_file_id":"1hgJhZvuH74KJ6sZmzXOtu5SWmdXaOtuD","authorship_tag":"ABX9TyMKODXlVpunLZT29Fbi79yq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"M1qhNexMbqoI","executionInfo":{"status":"ok","timestamp":1610908202139,"user_tz":-330,"elapsed":2072,"user":{"displayName":"vikas sao","photoUrl":"","userId":"08189896451819436987"}}},"source":["import time\r\n","import numpy as np\r\n","import pandas as pd\r\n","import seaborn as sns\r\n","import random\r\n","import math\r\n","import sys\r\n","import copy\r\n","import matplotlib.pyplot as plt \r\n","%matplotlib inline\r\n","from sklearn.preprocessing import LabelEncoder \r\n","from sklearn.model_selection import train_test_split\r\n","import warnings\r\n","warnings.filterwarnings('ignore') \r\n","from zipfile import ZipFile \r\n","\r\n","import tensorflow as tf\r\n","from tensorflow import keras\r\n","import sklearn\r\n","\r\n","#evaluation\r\n","from sklearn.metrics import accuracy_score , confusion_matrix, classification_report\r\n"," \r\n","\r\n"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nnx5K-Wob_oc","executionInfo":{"status":"ok","timestamp":1610908202143,"user_tz":-330,"elapsed":2065,"user":{"displayName":"vikas sao","photoUrl":"","userId":"08189896451819436987"}},"outputId":"d9b24ebc-c8ff-4f2e-b988-8579cfdaca6a"},"source":["tf.config.list_physical_devices()"],"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n"," PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"eNOppRy4cYo-","executionInfo":{"status":"ok","timestamp":1610908202145,"user_tz":-330,"elapsed":2054,"user":{"displayName":"vikas sao","photoUrl":"","userId":"08189896451819436987"}},"outputId":"d0404214-9b78-47c5-c5c2-020557e799de"},"source":["data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sonar_dataset.csv'  ,  header=None   )\r\n","data.head()\r\n","\r\n","\r\n"," "],"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","      <th>55</th>\n","      <th>56</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0200</td>\n","      <td>0.0371</td>\n","      <td>0.0428</td>\n","      <td>0.0207</td>\n","      <td>0.0954</td>\n","      <td>0.0986</td>\n","      <td>0.1539</td>\n","      <td>0.1601</td>\n","      <td>0.3109</td>\n","      <td>0.2111</td>\n","      <td>0.1609</td>\n","      <td>0.1582</td>\n","      <td>0.2238</td>\n","      <td>0.0645</td>\n","      <td>0.0660</td>\n","      <td>0.2273</td>\n","      <td>0.3100</td>\n","      <td>0.2999</td>\n","      <td>0.5078</td>\n","      <td>0.4797</td>\n","      <td>0.5783</td>\n","      <td>0.5071</td>\n","      <td>0.4328</td>\n","      <td>0.5550</td>\n","      <td>0.6711</td>\n","      <td>0.6415</td>\n","      <td>0.7104</td>\n","      <td>0.8080</td>\n","      <td>0.6791</td>\n","      <td>0.3857</td>\n","      <td>0.1307</td>\n","      <td>0.2604</td>\n","      <td>0.5121</td>\n","      <td>0.7547</td>\n","      <td>0.8537</td>\n","      <td>0.8507</td>\n","      <td>0.6692</td>\n","      <td>0.6097</td>\n","      <td>0.4943</td>\n","      <td>0.2744</td>\n","      <td>0.0510</td>\n","      <td>0.2834</td>\n","      <td>0.2825</td>\n","      <td>0.4256</td>\n","      <td>0.2641</td>\n","      <td>0.1386</td>\n","      <td>0.1051</td>\n","      <td>0.1343</td>\n","      <td>0.0383</td>\n","      <td>0.0324</td>\n","      <td>0.0232</td>\n","      <td>0.0027</td>\n","      <td>0.0065</td>\n","      <td>0.0159</td>\n","      <td>0.0072</td>\n","      <td>0.0167</td>\n","      <td>0.0180</td>\n","      <td>0.0084</td>\n","      <td>0.0090</td>\n","      <td>0.0032</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0453</td>\n","      <td>0.0523</td>\n","      <td>0.0843</td>\n","      <td>0.0689</td>\n","      <td>0.1183</td>\n","      <td>0.2583</td>\n","      <td>0.2156</td>\n","      <td>0.3481</td>\n","      <td>0.3337</td>\n","      <td>0.2872</td>\n","      <td>0.4918</td>\n","      <td>0.6552</td>\n","      <td>0.6919</td>\n","      <td>0.7797</td>\n","      <td>0.7464</td>\n","      <td>0.9444</td>\n","      <td>1.0000</td>\n","      <td>0.8874</td>\n","      <td>0.8024</td>\n","      <td>0.7818</td>\n","      <td>0.5212</td>\n","      <td>0.4052</td>\n","      <td>0.3957</td>\n","      <td>0.3914</td>\n","      <td>0.3250</td>\n","      <td>0.3200</td>\n","      <td>0.3271</td>\n","      <td>0.2767</td>\n","      <td>0.4423</td>\n","      <td>0.2028</td>\n","      <td>0.3788</td>\n","      <td>0.2947</td>\n","      <td>0.1984</td>\n","      <td>0.2341</td>\n","      <td>0.1306</td>\n","      <td>0.4182</td>\n","      <td>0.3835</td>\n","      <td>0.1057</td>\n","      <td>0.1840</td>\n","      <td>0.1970</td>\n","      <td>0.1674</td>\n","      <td>0.0583</td>\n","      <td>0.1401</td>\n","      <td>0.1628</td>\n","      <td>0.0621</td>\n","      <td>0.0203</td>\n","      <td>0.0530</td>\n","      <td>0.0742</td>\n","      <td>0.0409</td>\n","      <td>0.0061</td>\n","      <td>0.0125</td>\n","      <td>0.0084</td>\n","      <td>0.0089</td>\n","      <td>0.0048</td>\n","      <td>0.0094</td>\n","      <td>0.0191</td>\n","      <td>0.0140</td>\n","      <td>0.0049</td>\n","      <td>0.0052</td>\n","      <td>0.0044</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0262</td>\n","      <td>0.0582</td>\n","      <td>0.1099</td>\n","      <td>0.1083</td>\n","      <td>0.0974</td>\n","      <td>0.2280</td>\n","      <td>0.2431</td>\n","      <td>0.3771</td>\n","      <td>0.5598</td>\n","      <td>0.6194</td>\n","      <td>0.6333</td>\n","      <td>0.7060</td>\n","      <td>0.5544</td>\n","      <td>0.5320</td>\n","      <td>0.6479</td>\n","      <td>0.6931</td>\n","      <td>0.6759</td>\n","      <td>0.7551</td>\n","      <td>0.8929</td>\n","      <td>0.8619</td>\n","      <td>0.7974</td>\n","      <td>0.6737</td>\n","      <td>0.4293</td>\n","      <td>0.3648</td>\n","      <td>0.5331</td>\n","      <td>0.2413</td>\n","      <td>0.5070</td>\n","      <td>0.8533</td>\n","      <td>0.6036</td>\n","      <td>0.8514</td>\n","      <td>0.8512</td>\n","      <td>0.5045</td>\n","      <td>0.1862</td>\n","      <td>0.2709</td>\n","      <td>0.4232</td>\n","      <td>0.3043</td>\n","      <td>0.6116</td>\n","      <td>0.6756</td>\n","      <td>0.5375</td>\n","      <td>0.4719</td>\n","      <td>0.4647</td>\n","      <td>0.2587</td>\n","      <td>0.2129</td>\n","      <td>0.2222</td>\n","      <td>0.2111</td>\n","      <td>0.0176</td>\n","      <td>0.1348</td>\n","      <td>0.0744</td>\n","      <td>0.0130</td>\n","      <td>0.0106</td>\n","      <td>0.0033</td>\n","      <td>0.0232</td>\n","      <td>0.0166</td>\n","      <td>0.0095</td>\n","      <td>0.0180</td>\n","      <td>0.0244</td>\n","      <td>0.0316</td>\n","      <td>0.0164</td>\n","      <td>0.0095</td>\n","      <td>0.0078</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0100</td>\n","      <td>0.0171</td>\n","      <td>0.0623</td>\n","      <td>0.0205</td>\n","      <td>0.0205</td>\n","      <td>0.0368</td>\n","      <td>0.1098</td>\n","      <td>0.1276</td>\n","      <td>0.0598</td>\n","      <td>0.1264</td>\n","      <td>0.0881</td>\n","      <td>0.1992</td>\n","      <td>0.0184</td>\n","      <td>0.2261</td>\n","      <td>0.1729</td>\n","      <td>0.2131</td>\n","      <td>0.0693</td>\n","      <td>0.2281</td>\n","      <td>0.4060</td>\n","      <td>0.3973</td>\n","      <td>0.2741</td>\n","      <td>0.3690</td>\n","      <td>0.5556</td>\n","      <td>0.4846</td>\n","      <td>0.3140</td>\n","      <td>0.5334</td>\n","      <td>0.5256</td>\n","      <td>0.2520</td>\n","      <td>0.2090</td>\n","      <td>0.3559</td>\n","      <td>0.6260</td>\n","      <td>0.7340</td>\n","      <td>0.6120</td>\n","      <td>0.3497</td>\n","      <td>0.3953</td>\n","      <td>0.3012</td>\n","      <td>0.5408</td>\n","      <td>0.8814</td>\n","      <td>0.9857</td>\n","      <td>0.9167</td>\n","      <td>0.6121</td>\n","      <td>0.5006</td>\n","      <td>0.3210</td>\n","      <td>0.3202</td>\n","      <td>0.4295</td>\n","      <td>0.3654</td>\n","      <td>0.2655</td>\n","      <td>0.1576</td>\n","      <td>0.0681</td>\n","      <td>0.0294</td>\n","      <td>0.0241</td>\n","      <td>0.0121</td>\n","      <td>0.0036</td>\n","      <td>0.0150</td>\n","      <td>0.0085</td>\n","      <td>0.0073</td>\n","      <td>0.0050</td>\n","      <td>0.0044</td>\n","      <td>0.0040</td>\n","      <td>0.0117</td>\n","      <td>R</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0762</td>\n","      <td>0.0666</td>\n","      <td>0.0481</td>\n","      <td>0.0394</td>\n","      <td>0.0590</td>\n","      <td>0.0649</td>\n","      <td>0.1209</td>\n","      <td>0.2467</td>\n","      <td>0.3564</td>\n","      <td>0.4459</td>\n","      <td>0.4152</td>\n","      <td>0.3952</td>\n","      <td>0.4256</td>\n","      <td>0.4135</td>\n","      <td>0.4528</td>\n","      <td>0.5326</td>\n","      <td>0.7306</td>\n","      <td>0.6193</td>\n","      <td>0.2032</td>\n","      <td>0.4636</td>\n","      <td>0.4148</td>\n","      <td>0.4292</td>\n","      <td>0.5730</td>\n","      <td>0.5399</td>\n","      <td>0.3161</td>\n","      <td>0.2285</td>\n","      <td>0.6995</td>\n","      <td>1.0000</td>\n","      <td>0.7262</td>\n","      <td>0.4724</td>\n","      <td>0.5103</td>\n","      <td>0.5459</td>\n","      <td>0.2881</td>\n","      <td>0.0981</td>\n","      <td>0.1951</td>\n","      <td>0.4181</td>\n","      <td>0.4604</td>\n","      <td>0.3217</td>\n","      <td>0.2828</td>\n","      <td>0.2430</td>\n","      <td>0.1979</td>\n","      <td>0.2444</td>\n","      <td>0.1847</td>\n","      <td>0.0841</td>\n","      <td>0.0692</td>\n","      <td>0.0528</td>\n","      <td>0.0357</td>\n","      <td>0.0085</td>\n","      <td>0.0230</td>\n","      <td>0.0046</td>\n","      <td>0.0156</td>\n","      <td>0.0031</td>\n","      <td>0.0054</td>\n","      <td>0.0105</td>\n","      <td>0.0110</td>\n","      <td>0.0015</td>\n","      <td>0.0072</td>\n","      <td>0.0048</td>\n","      <td>0.0107</td>\n","      <td>0.0094</td>\n","      <td>R</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       0       1       2       3       4   ...      56      57      58      59  60\n","0  0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032   R\n","1  0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044   R\n","2  0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078   R\n","3  0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117   R\n","4  0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094   R\n","\n","[5 rows x 61 columns]"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"51dsB-2Pdb8U","executionInfo":{"status":"ok","timestamp":1610908202147,"user_tz":-330,"elapsed":2043,"user":{"displayName":"vikas sao","photoUrl":"","userId":"08189896451819436987"}},"outputId":"a565a66b-ecdd-4941-cf22-8071b205fc01"},"source":["X = data.drop([60] ,axis =1)\r\n","Y = data[60]\r\n","le =LabelEncoder()\r\n","Y = le.fit_transform(Y)\r\n","print(X)\r\n","print(Y)"],"execution_count":60,"outputs":[{"output_type":"stream","text":["         0       1       2       3   ...      56      57      58      59\n","0    0.0200  0.0371  0.0428  0.0207  ...  0.0180  0.0084  0.0090  0.0032\n","1    0.0453  0.0523  0.0843  0.0689  ...  0.0140  0.0049  0.0052  0.0044\n","2    0.0262  0.0582  0.1099  0.1083  ...  0.0316  0.0164  0.0095  0.0078\n","3    0.0100  0.0171  0.0623  0.0205  ...  0.0050  0.0044  0.0040  0.0117\n","4    0.0762  0.0666  0.0481  0.0394  ...  0.0072  0.0048  0.0107  0.0094\n","..      ...     ...     ...     ...  ...     ...     ...     ...     ...\n","203  0.0187  0.0346  0.0168  0.0177  ...  0.0065  0.0115  0.0193  0.0157\n","204  0.0323  0.0101  0.0298  0.0564  ...  0.0034  0.0032  0.0062  0.0067\n","205  0.0522  0.0437  0.0180  0.0292  ...  0.0140  0.0138  0.0077  0.0031\n","206  0.0303  0.0353  0.0490  0.0608  ...  0.0034  0.0079  0.0036  0.0048\n","207  0.0260  0.0363  0.0136  0.0272  ...  0.0040  0.0036  0.0061  0.0115\n","\n","[208 rows x 60 columns]\n","[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"123Oeli2fKQK","executionInfo":{"status":"ok","timestamp":1610908202149,"user_tz":-330,"elapsed":2034,"user":{"displayName":"vikas sao","photoUrl":"","userId":"08189896451819436987"}},"outputId":"aa1a526b-9f46-4f94-acaa-014181ab3a12"},"source":["X_train ,X_test ,Y_train , Y_test = train_test_split(X, Y ,random_state =0)\r\n","print(X_train.shape)\r\n","print(X_test.shape)\r\n"],"execution_count":61,"outputs":[{"output_type":"stream","text":["(156, 60)\n","(52, 60)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QAFou0xifaaM","executionInfo":{"status":"ok","timestamp":1610908208004,"user_tz":-330,"elapsed":7877,"user":{"displayName":"vikas sao","photoUrl":"","userId":"08189896451819436987"}},"outputId":"c53a1342-b1df-4a70-cb6e-d941c4796efd"},"source":["# wihtout using the dropout\r\n","\r\n","\r\n","model  = keras.Sequential([\r\n","      keras.layers.Dense(60 ,input_dim =60 , activation='relu') ,\r\n","      keras.layers.Dense(30 ,  activation='relu') ,\r\n","      keras.layers.Dense(10  , activation='relu') ,\r\n","      keras.layers.Dense(1 , activation='sigmoid')\r\n","      \r\n","])\r\n","model.compile(\r\n","    optimizer ='adam' ,\r\n","    loss = 'binary_crossentropy' ,\r\n","    metrics =['accuracy']\r\n",")\r\n","model.fit(X_train,Y_train, epochs =100 , batch_size=8 )\r\n"],"execution_count":62,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.7088 - accuracy: 0.4381\n","Epoch 2/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.6074\n","Epoch 3/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6303\n","Epoch 4/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.6315\n","Epoch 5/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.6879\n","Epoch 6/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.6684\n","Epoch 7/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7440\n","Epoch 8/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7223\n","Epoch 9/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7991\n","Epoch 10/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8170\n","Epoch 11/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7916\n","Epoch 12/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7549\n","Epoch 13/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8049\n","Epoch 14/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.3443 - accuracy: 0.8303\n","Epoch 15/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8658\n","Epoch 16/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8978\n","Epoch 17/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8925\n","Epoch 18/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8663\n","Epoch 19/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.9252\n","Epoch 20/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.8756\n","Epoch 21/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.2924 - accuracy: 0.8735\n","Epoch 22/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8516\n","Epoch 23/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.2370 - accuracy: 0.9265\n","Epoch 24/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.8916\n","Epoch 25/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.2592 - accuracy: 0.9037\n","Epoch 26/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9368\n","Epoch 27/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.8665\n","Epoch 28/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.8971\n","Epoch 29/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.9279\n","Epoch 30/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.1825 - accuracy: 0.9288\n","Epoch 31/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9727\n","Epoch 32/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.2228 - accuracy: 0.9152\n","Epoch 33/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9693\n","Epoch 34/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.1438 - accuracy: 0.9691\n","Epoch 35/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.9885\n","Epoch 36/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.9781\n","Epoch 37/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.9709\n","Epoch 38/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9541\n","Epoch 39/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0899 - accuracy: 0.9937\n","Epoch 40/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.9777\n","Epoch 41/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0808 - accuracy: 0.9850\n","Epoch 42/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9770\n","Epoch 43/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.9851\n","Epoch 44/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9980\n","Epoch 45/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9863\n","Epoch 46/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 1.0000\n","Epoch 47/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9919\n","Epoch 48/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 1.0000\n","Epoch 49/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9872\n","Epoch 50/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 1.0000\n","Epoch 51/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9866\n","Epoch 52/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9820\n","Epoch 53/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9907\n","Epoch 54/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9892\n","Epoch 55/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 1.0000\n","Epoch 56/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 1.0000\n","Epoch 57/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 1.0000\n","Epoch 58/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 1.0000\n","Epoch 59/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000\n","Epoch 60/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 1.0000\n","Epoch 61/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 1.0000\n","Epoch 62/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 1.0000\n","Epoch 63/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 1.0000\n","Epoch 64/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 1.0000\n","Epoch 65/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 1.0000\n","Epoch 66/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000\n","Epoch 67/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 1.0000\n","Epoch 68/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 1.0000\n","Epoch 69/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000\n","Epoch 70/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000\n","Epoch 71/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n","Epoch 72/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n","Epoch 73/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000\n","Epoch 74/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n","Epoch 75/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n","Epoch 76/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n","Epoch 77/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n","Epoch 78/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n","Epoch 79/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n","Epoch 80/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n","Epoch 81/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n","Epoch 82/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000\n","Epoch 83/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n","Epoch 84/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000\n","Epoch 85/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n","Epoch 86/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n","Epoch 87/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 88/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 89/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n","Epoch 90/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 91/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n","Epoch 92/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 93/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n","Epoch 94/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n","Epoch 95/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 96/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 97/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 98/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n","Epoch 99/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 100/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fea0b17c160>"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CFkzupleaC7r","executionInfo":{"status":"ok","timestamp":1610908208036,"user_tz":-330,"elapsed":7898,"user":{"displayName":"vikas sao","photoUrl":"","userId":"08189896451819436987"}},"outputId":"1f3dfc67-545f-4d24-c46f-8230c8565710"},"source":["predict = np.round(model.predict(X_test))\r\n","predict.shape = (52 ,)\r\n","print(Y_test[0:10])\r\n","print(predict[0:10])\r\n","cm = confusion_matrix(Y_test, predict)\r\n","print(classification_report(Y_test ,predict))\r\n","\r\n"],"execution_count":63,"outputs":[{"output_type":"stream","text":["[1 1 1 1 0 1 0 0 1 0]\n","[0. 1. 0. 1. 0. 1. 0. 0. 1. 0.]\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.92      0.84        26\n","           1       0.90      0.73      0.81        26\n","\n","    accuracy                           0.83        52\n","   macro avg       0.84      0.83      0.83        52\n","weighted avg       0.84      0.83      0.83        52\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dwFQGti4auD7","executionInfo":{"status":"ok","timestamp":1610908213233,"user_tz":-330,"elapsed":13085,"user":{"displayName":"vikas sao","photoUrl":"","userId":"08189896451819436987"}},"outputId":"e6c3566c-8438-4055-ec89-c6d5dcd29fdf"},"source":["#  using the dropout\r\n","\r\n","\r\n","model  = keras.Sequential([\r\n","      keras.layers.Dense(60 ,input_dim =60 , activation='relu') ,\r\n","      keras.layers.Dropout(.5) ,\r\n","      keras.layers.Dense(30 ,  activation='relu') ,\r\n","      keras.layers.Dropout(.5) ,\r\n","\r\n","      keras.layers.Dense(15  , activation='relu') ,\r\n","      keras.layers.Dropout(.5) , \r\n","      keras.layers.Dense(1 , activation='sigmoid')\r\n","      \r\n","])\r\n","model.compile(\r\n","    optimizer ='adam' ,\r\n","    loss = 'binary_crossentropy' ,\r\n","    metrics =['accuracy']\r\n",")\r\n","\r\n","model.fit(X_train,Y_train, epochs =100 , batch_size=8 )\r\n"],"execution_count":64,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.7051 - accuracy: 0.5859\n","Epoch 2/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5098\n","Epoch 3/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.5619\n","Epoch 4/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.6170\n","Epoch 5/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.7177 - accuracy: 0.4672\n","Epoch 6/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6773 - accuracy: 0.5779\n","Epoch 7/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6719 - accuracy: 0.6221\n","Epoch 8/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.5597\n","Epoch 9/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.5245\n","Epoch 10/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.7252 - accuracy: 0.4532\n","Epoch 11/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6667\n","Epoch 12/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.5965\n","Epoch 13/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.5357\n","Epoch 14/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.5760\n","Epoch 15/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.6711\n","Epoch 16/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6141\n","Epoch 17/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.6171\n","Epoch 18/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.5986\n","Epoch 19/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.5710\n","Epoch 20/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.5932\n","Epoch 21/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6481\n","Epoch 22/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.7164 - accuracy: 0.5432\n","Epoch 23/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.6512\n","Epoch 24/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.6577\n","Epoch 25/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.6713\n","Epoch 26/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.5707\n","Epoch 27/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.6860\n","Epoch 28/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7158\n","Epoch 29/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.6044\n","Epoch 30/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.7341\n","Epoch 31/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6049 - accuracy: 0.7455\n","Epoch 32/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.6710\n","Epoch 33/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.7061\n","Epoch 34/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7164\n","Epoch 35/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.6728\n","Epoch 36/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7798\n","Epoch 37/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.6120\n","Epoch 38/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7527\n","Epoch 39/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7316\n","Epoch 40/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7398\n","Epoch 41/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7208\n","Epoch 42/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7452\n","Epoch 43/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6977\n","Epoch 44/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7572\n","Epoch 45/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7669\n","Epoch 46/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7741\n","Epoch 47/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7104\n","Epoch 48/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7361\n","Epoch 49/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7735\n","Epoch 50/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7939\n","Epoch 51/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8402\n","Epoch 52/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7395\n","Epoch 53/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7635\n","Epoch 54/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7832\n","Epoch 55/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7165\n","Epoch 56/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7905\n","Epoch 57/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7518\n","Epoch 58/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7836\n","Epoch 59/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7656\n","Epoch 60/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8266\n","Epoch 61/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7510\n","Epoch 62/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7516\n","Epoch 63/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8341\n","Epoch 64/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8143\n","Epoch 65/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8099\n","Epoch 66/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7561\n","Epoch 67/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.8092\n","Epoch 68/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7832\n","Epoch 69/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8047\n","Epoch 70/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8419\n","Epoch 71/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8111\n","Epoch 72/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8395\n","Epoch 73/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8319\n","Epoch 74/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8385\n","Epoch 75/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.8298\n","Epoch 76/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8481\n","Epoch 77/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8103\n","Epoch 78/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8512\n","Epoch 79/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.8765\n","Epoch 80/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.8078\n","Epoch 81/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8652\n","Epoch 82/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.9076\n","Epoch 83/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8146\n","Epoch 84/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8305\n","Epoch 85/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8462\n","Epoch 86/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.9101\n","Epoch 87/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8675\n","Epoch 88/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8590\n","Epoch 89/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7782\n","Epoch 90/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8398\n","Epoch 91/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8395\n","Epoch 92/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8859\n","Epoch 93/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.9144\n","Epoch 94/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.8679\n","Epoch 95/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8655\n","Epoch 96/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.3550 - accuracy: 0.8517\n","Epoch 97/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8563\n","Epoch 98/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.9062\n","Epoch 99/100\n","20/20 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8637\n","Epoch 100/100\n","20/20 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8304\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fea09ffe0f0>"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oftr3tqrfp4R","executionInfo":{"status":"ok","timestamp":1610908213239,"user_tz":-330,"elapsed":13081,"user":{"displayName":"vikas sao","photoUrl":"","userId":"08189896451819436987"}},"outputId":"a659c93d-c2e1-461f-8ba2-66b52f386630"},"source":["predict = np.round(model.predict(X_test))\r\n","predict.shape = (52 ,)\r\n","print(Y_test[0:10])\r\n","print(predict[0:10])\r\n","cm = confusion_matrix(Y_test, predict)\r\n","print(cm)\r\n","print(classification_report(Y_test ,predict))\r\n","\r\n","\r\n"],"execution_count":65,"outputs":[{"output_type":"stream","text":["[1 1 1 1 0 1 0 0 1 0]\n","[0. 0. 0. 1. 0. 1. 0. 0. 1. 0.]\n","[[25  1]\n"," [ 9 17]]\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.96      0.83        26\n","           1       0.94      0.65      0.77        26\n","\n","    accuracy                           0.81        52\n","   macro avg       0.84      0.81      0.80        52\n","weighted avg       0.84      0.81      0.80        52\n","\n"],"name":"stdout"}]}]}